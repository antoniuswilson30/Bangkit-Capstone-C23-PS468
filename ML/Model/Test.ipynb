{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, re, time, json\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../Dataset/train/acne/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax, color=(255, 0, 0), thickness=5):\n",
    "    \"\"\"\n",
    "    Adds a bounding box to an image.\n",
    "    Bounding box coordinates can be specified in either absolute (pixel) or\n",
    "    normalized coordinates by setting the use_normalized_coordinates argument.\n",
    "    \n",
    "    Args:\n",
    "      image: a PIL.Image object.\n",
    "      ymin: ymin of bounding box.\n",
    "      xmin: xmin of bounding box.\n",
    "      ymax: ymax of bounding box.\n",
    "      xmax: xmax of bounding box.\n",
    "      color: color to draw bounding box. Default is red.\n",
    "      thickness: line thickness. Default value is 4.\n",
    "    \"\"\"\n",
    "  \n",
    "    image_width = image.shape[1]\n",
    "    image_height = image.shape[0]\n",
    "    cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), color, thickness)\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image(image, boxes, color=[], thickness=5):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes on image.\n",
    "    \n",
    "    Args:\n",
    "      image: a PIL.Image object.\n",
    "      boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "             The coordinates are in normalized format between [0, 1].\n",
    "      color: color to draw bounding box. Default is red.\n",
    "      thickness: line thickness. Default value is 4.\n",
    "                           \n",
    "    Raises:\n",
    "      ValueError: if boxes is not a [N, 4] array\n",
    "    \"\"\"\n",
    "    \n",
    "    boxes_shape = boxes.shape\n",
    "    if not boxes_shape:\n",
    "        return\n",
    "    if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
    "        raise ValueError('Input must be of size [N, 4]')\n",
    "    for i in range(boxes_shape[0]):\n",
    "        draw_bounding_box_on_image(image, boxes[i, 1], boxes[i, 0], boxes[i, 3],\n",
    "                                 boxes[i, 2], color[i], thickness)\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image_array(image, boxes, color=[], thickness=5):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes on image (numpy array).\n",
    "    \n",
    "    Args:\n",
    "      image: a numpy array object.\n",
    "      boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "             The coordinates are in normalized format between [0, 1].\n",
    "      color: color to draw bounding box. Default is red.\n",
    "      thickness: line thickness. Default value is 4.\n",
    "      display_str_list_list: a list of strings for each bounding box.\n",
    "    \n",
    "    Raises:\n",
    "      ValueError: if boxes is not a [N, 4] array\n",
    "    \"\"\"\n",
    "\n",
    "    draw_bounding_boxes_on_image(image, boxes, color, thickness)\n",
    "  \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib config\n",
    "plt.rc('image', cmap='gray')\n",
    "plt.rc('grid', linewidth=0)\n",
    "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
    "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
    "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
    "plt.rc('text', color='a8151a')\n",
    "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
    "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
    "\n",
    "\n",
    "# utility to display a row of digits with their predictions\n",
    "def display_digits_with_boxes(images, pred_bboxes, bboxes, iou, title, bboxes_normalized=False):\n",
    "\n",
    "    n = len(images)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    plt.title(title)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "  \n",
    "    for i in range(n):\n",
    "      ax = fig.add_subplot(1, 10, i+1)\n",
    "      bboxes_to_plot = []\n",
    "      if (len(pred_bboxes) > i):\n",
    "        bbox = pred_bboxes[i]\n",
    "        bbox = [bbox[0] * images[i].shape[1], bbox[1] * images[i].shape[0], bbox[2] * images[i].shape[1], bbox[3] * images[i].shape[0]]\n",
    "        bboxes_to_plot.append(bbox)\n",
    "    \n",
    "      if (len(bboxes) > i):\n",
    "        bbox = bboxes[i]\n",
    "        if bboxes_normalized == True:\n",
    "          bbox = [bbox[0] * images[i].shape[1],bbox[1] * images[i].shape[0], bbox[2] * images[i].shape[1], bbox[3] * images[i].shape[0] ]\n",
    "        bboxes_to_plot.append(bbox)\n",
    "\n",
    "      img_to_draw = draw_bounding_boxes_on_image_array(image=images[i], boxes=np.asarray(bboxes_to_plot), color=[(255,0,0), (0, 255, 0)])\n",
    "      plt.xticks([])\n",
    "      plt.yticks([])\n",
    "    \n",
    "      plt.imshow(img_to_draw)\n",
    "\n",
    "      if len(iou) > i :\n",
    "        color = \"black\"\n",
    "        if (iou[i][0] < iou_threshold):\n",
    "          color = \"red\"\n",
    "        ax.text(0.2, -0.3, \"iou: %s\" %(iou[i][0]), color=color, transform=ax.transAxes)\n",
    "        \n",
    "        \n",
    "# utility to display training and validation curves\n",
    "def plot_metrics(metric_name, title, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.plot(history.history[metric_name],color='blue',label=metric_name)\n",
    "    plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_tfds(image, bbox):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    shape = tf.shape(image)\n",
    "\n",
    "    factor_x = tf.cast(shape[1], tf.float32)\n",
    "    factor_y = tf.cast(shape[0], tf.float32)\n",
    "\n",
    "    image = tf.image.resize(image, (224, 224,))\n",
    "\n",
    "    image = image/127.5\n",
    "    image -= 1\n",
    "\n",
    "    bbox_list = [bbox[0] / factor_x , \n",
    "                 bbox[1] / factor_y, \n",
    "                 bbox[2] / factor_x , \n",
    "                 bbox[3] / factor_y]\n",
    "    \n",
    "    return image, bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_with_shape(image, bbox):\n",
    "    original_image = image\n",
    "    \n",
    "    image, bbox_list = read_image_tfds(image, bbox)\n",
    "    \n",
    "    return original_image, image, bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_tfds_with_original_bbox(data):\n",
    "    image = data[\"image\"]\n",
    "    bbox = data[\"bbox\"]\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    factor_x = tf.cast(shape[1], tf.float32) \n",
    "    factor_y = tf.cast(shape[0], tf.float32)\n",
    "\n",
    "    bbox_list = [bbox[1] * factor_x , \n",
    "                 bbox[0] * factor_y, \n",
    "                 bbox[3] * factor_x, \n",
    "                 bbox[2] * factor_y]\n",
    "    return image, bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy_util(dataset, batch_size=0, N=0):\n",
    "\n",
    "    # eager execution: loop through datasets normally\n",
    "    take_dataset = dataset.shuffle(1024)\n",
    "\n",
    "    if batch_size > 0:\n",
    "        take_dataset = take_dataset.batch(batch_size)\n",
    "  \n",
    "    if N > 0:\n",
    "        take_dataset = take_dataset.take(N)\n",
    "  \n",
    "    if tf.executing_eagerly():\n",
    "        ds_images, ds_bboxes = [], []\n",
    "        for images, bboxes in take_dataset:\n",
    "            ds_images.append(images.numpy())\n",
    "            ds_bboxes.append(bboxes.numpy())\n",
    "        \n",
    "    return (np.array(ds_images), np.array(ds_bboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy_with_original_bboxes_util(dataset, batch_size=0, N=0):\n",
    "\n",
    "    normalized_dataset = dataset.map(read_image_with_shape)\n",
    "    if batch_size > 0:\n",
    "        normalized_dataset = normalized_dataset.batch(batch_size)\n",
    "  \n",
    "    if N > 0:\n",
    "        normalized_dataset = normalized_dataset.take(N)\n",
    "\n",
    "    if tf.executing_eagerly():\n",
    "        ds_original_images, ds_images, ds_bboxes = [], [], []\n",
    "        \n",
    "    for original_images, images, bboxes in normalized_dataset:\n",
    "        ds_images.append(images.numpy())\n",
    "        ds_bboxes.append(bboxes.numpy())\n",
    "        ds_original_images.append(original_images.numpy())\n",
    "\n",
    "    return np.array(ds_original_images), np.array(ds_images), np.array(ds_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1644 files belonging to 2 classes.\n",
      "Using 1316 files for training.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_19884\\913943050.py\", line 20, in None  *\n        lambda image, bbox: read_image_with_original_bbox(image, bbox)\n    File \"C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_19884\\913943050.py\", line 4, in read_image_with_original_bbox  *\n        image = cv2.imread(image_path)\n\n    TypeError: Can't convert object to 'str' for 'filename'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m     visualization_training_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\n\u001b[0;32m     20\u001b[0m         \u001b[39mlambda\u001b[39;00m image, bbox: read_image_with_original_bbox(image, bbox), num_parallel_calls\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m\n\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m visualization_training_dataset\n\u001b[1;32m---> 24\u001b[0m visualization_training_dataset \u001b[39m=\u001b[39m get_visualization_training_dataset(\u001b[39m\"\u001b[39;49m\u001b[39m../Model/image/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     26\u001b[0m (visualization_training_images, visualization_training_bboxes) \u001b[39m=\u001b[39m dataset_to_numpy_util(\n\u001b[0;32m     27\u001b[0m     visualization_training_dataset, N\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m display_digits_with_boxes(\n\u001b[0;32m     31\u001b[0m     np\u001b[39m.\u001b[39marray(visualization_training_images),\n\u001b[0;32m     32\u001b[0m     np\u001b[39m.\u001b[39marray([]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtraining images and their bboxes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m )\n",
      "Cell \u001b[1;32mIn[26], line 19\u001b[0m, in \u001b[0;36mget_visualization_training_dataset\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_visualization_training_dataset\u001b[39m(data_dir):\n\u001b[0;32m     10\u001b[0m     dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     11\u001b[0m         data_dir,\n\u001b[0;32m     12\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m         seed\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[1;32m---> 19\u001b[0m     visualization_training_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m     20\u001b[0m         \u001b[39mlambda\u001b[39;49;00m image, bbox: read_image_with_original_bbox(image, bbox), num_parallel_calls\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m\n\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m visualization_training_dataset\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2236\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2237\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2238\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[0;32m   2241\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2242\u001b[0m     map_func,\n\u001b[0;32m   2243\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[0;32m   2244\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[0;32m   2245\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[0;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     41\u001b[0m       input_dataset,\n\u001b[0;32m     42\u001b[0m       map_func,\n\u001b[0;32m     43\u001b[0m       num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[0;32m     44\u001b[0m       deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[0;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     46\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[0;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m--> 148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m    149\u001b[0m     map_func,\n\u001b[0;32m    150\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m    151\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m    152\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deterministic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    255\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    262\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    224\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[0;32m    233\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    234\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    235\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[0;32m    201\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 202\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    203\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    204\u001b[0m   concrete_function\u001b[39m.\u001b[39m_arg_keywords \u001b[39m=\u001b[39m []  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    164\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[0;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m    299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 300\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    301\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    303\u001b[0m         args,\n\u001b[0;32m    304\u001b[0m         kwargs,\n\u001b[0;32m    305\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[0;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    313\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    233\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    235\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    239\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    240\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    168\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 169\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    170\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filer593c5ek.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(image, bbox)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m image, bbox: ag__\u001b[39m.\u001b[39;49mwith_function_scope(\u001b[39mlambda\u001b[39;49;00m lscope: ag__\u001b[39m.\u001b[39;49mconverted_call(read_image_with_original_bbox, (image, bbox), \u001b[39mNone\u001b[39;49;00m, lscope), \u001b[39m'\u001b[39;49m\u001b[39mlscope\u001b[39;49m\u001b[39m'\u001b[39;49m, ag__\u001b[39m.\u001b[39;49mSTD)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[1;34m(thunk, scope_name, options)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m FunctionScope(\u001b[39m'\u001b[39m\u001b[39mlambda_\u001b[39m\u001b[39m'\u001b[39m, scope_name, options) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m--> 113\u001b[0m   \u001b[39mreturn\u001b[39;00m thunk(scope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filer593c5ek.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(lscope)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m image, bbox: ag__\u001b[39m.\u001b[39mwith_function_scope(\u001b[39mlambda\u001b[39;00m lscope: ag__\u001b[39m.\u001b[39;49mconverted_call(read_image_with_original_bbox, (image, bbox), \u001b[39mNone\u001b[39;49;00m, lscope), \u001b[39m'\u001b[39m\u001b[39mlscope\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mSTD)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezuz7uv96.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__read_image_with_original_bbox\u001b[1;34m(image_path, bbox)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m image \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(cv2)\u001b[39m.\u001b[39;49mimread, (ag__\u001b[39m.\u001b[39;49mld(image_path),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     11\u001b[0m processed_image \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(cv2)\u001b[39m.\u001b[39mresize, (ag__\u001b[39m.\u001b[39mld(image), (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m processed_bbox \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(bbox)\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:371\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[39mreturn\u001b[39;00m py_builtins\u001b[39m.\u001b[39moverload_of(f)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    370\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 371\u001b[0m     \u001b[39mreturn\u001b[39;00m py_builtins\u001b[39m.\u001b[39;49moverload_of(f)(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_unsupported(f):\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_19884\\913943050.py\", line 20, in None  *\n        lambda image, bbox: read_image_with_original_bbox(image, bbox)\n    File \"C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_19884\\913943050.py\", line 4, in read_image_with_original_bbox  *\n        image = cv2.imread(image_path)\n\n    TypeError: Can't convert object to 'str' for 'filename'\n"
     ]
    }
   ],
   "source": [
    "def read_image_with_original_bbox(image_path, bbox):\n",
    "    # Custom code to read and process the image and its bounding box\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    processed_image = cv2.resize(image, (224, 224))\n",
    "    processed_bbox = bbox\n",
    "    return processed_image, processed_bbox\n",
    "\n",
    "def get_visualization_training_dataset(data_dir):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        batch_size=32,\n",
    "        image_size=(224, 224),\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123\n",
    "    )\n",
    "\n",
    "    visualization_training_dataset = dataset.map(\n",
    "        lambda image, bbox: read_image_with_original_bbox(image, bbox), num_parallel_calls=16\n",
    "    )\n",
    "    return visualization_training_dataset\n",
    "\n",
    "visualization_training_dataset = get_visualization_training_dataset(\"../Model/image/\")\n",
    "\n",
    "(visualization_training_images, visualization_training_bboxes) = dataset_to_numpy_util(\n",
    "    visualization_training_dataset, N=10\n",
    ")\n",
    "\n",
    "display_digits_with_boxes(\n",
    "    np.array(visualization_training_images),\n",
    "    np.array([]),\n",
    "    np.array(visualization_training_bboxes),\n",
    "    np.array([]),\n",
    "    \"training images and their bboxes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(\"./image/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./image/\n"
     ]
    }
   ],
   "source": [
    "print(\"./image/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
